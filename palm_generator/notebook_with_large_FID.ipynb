{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "#!apt-get update && apt-get install ffmpeg libsm6 libxext6  -y\n",
    "#!pip install mediapipe\n",
    "#!pip install opencv-python transformers accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1728759673_'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "t = str(int(time.time()))+\"_\"\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12 19:01:19.452738: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-12 19:01:19.452821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-12 19:01:19.452856: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from diffusers import AutoencoderKL, StableDiffusionXLControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from controlnet_aux import OpenposeDetector\n",
    "from diffusers.utils import load_image\n",
    "from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline, AutoencoderKL\n",
    "from diffusers import DDIMScheduler, EulerAncestralDiscreteScheduler\n",
    "from controlnet_aux import MidasDetector\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b28b9f925a4b37b35bdac3ce7af4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controlnet_conditioning_scale = 1.0  \n",
    "prompt = \"A detailed, high-quality photograph, high-quality  realistically, well lit, of a human palm on a pure white background. White background.The palm is facing the viewer, fingers extended, with the pattern of creases and lines on the hand clearly visible. There are no other objects or elements in the image.\"\n",
    "negative_prompt = \"not a palm, drawn, cartoons, animation, drawing, Blurriness, (many folds), low resolution, other body parts, extraneous objects, background elements, jewelry, tattoos, text, watermarks, multiple hands, gloves, nail polish, distracting details.\"\n",
    "\n",
    "\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"xinsir/controlnet-depth-sdxl-1.0\",\n",
    "    torch_dtype=torch.float16, cache_dir='./modele cache/'\n",
    ")\n",
    "\n",
    "# when test with other base model, you need to change the vae also.\n",
    "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16, cache_dir='./modele cache/')\n",
    "\n",
    "eulera_scheduler = EulerAncestralDiscreteScheduler.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", subfolder=\"scheduler\",cache_dir='./modele cache/')\n",
    "\n",
    "\n",
    "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "    \"John6666/realism-by-stable-yogi-sdxlv2-sdxl\",\n",
    "    controlnet=controlnet,\n",
    "    vae=vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    scheduler=eulera_scheduler,\n",
    "    cache_dir='./modele cache/'\n",
    ").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728759696.498418   37937 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1728759696.539393   37937 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a266cae821d54f1d9577e69e1327610c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728759742.885902   37970 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "/root/miniconda3/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вероятность 97.93%\n",
      "Рука не обнаружена на изображении.\n",
      "Рука не обнаружена на изображении.\n",
      "Рука не обнаружена на изображении.\n",
      "вероятность 97.77%\n",
      "вероятность 98.00%\n",
      "вероятность 95.31%\n",
      "вероятность 98.33%\n",
      "вероятность 96.76%\n",
      "Рука не обнаружена на изображении.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e30a4c1769342f997709a0c2f08f148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вероятность 96.72%\n",
      "вероятность 96.75%\n",
      "вероятность 96.39%\n",
      "Рука не обнаружена на изображении.\n",
      "вероятность 97.62%\n",
      "вероятность 96.16%\n",
      "вероятность 96.97%\n",
      "вероятность 95.98%\n",
      "вероятность 85.86%\n",
      "Рука не обнаружена на изображении.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bc69f2f7e2424d81403529b3ad7370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вероятность 91.33%\n",
      "вероятность 97.59%\n",
      "вероятность 93.37%\n",
      "вероятность 97.77%\n",
      "вероятность 98.52%\n",
      "вероятность 98.02%\n",
      "Рука не обнаружена на изображении.\n",
      "вероятность 97.38%\n",
      "вероятность 97.19%\n",
      "вероятность 94.48%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaff19ee16a4db699862f1e3376dbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "# Инициализация MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=True,        # Режим обработки статичного изображения\n",
    "    max_num_hands=1,               # Максимальное количество рук для обнаружения\n",
    "    min_detection_confidence=0.95   # Установите порог для обнаружения\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for i in range(200):\n",
    "    # Получаем случайный файл маски\n",
    "    mask_files = [f for f in os.listdir('./masks/') if f.endswith((\".jpg\", \".png\"))]\n",
    "    random_mask_file = random.choice(mask_files)\n",
    "    controlnet_img = Image.open('./masks/' + random_mask_file).convert(\"L\")  # Преобразуем в черно-белый формат\n",
    "    width, height = controlnet_img.size\n",
    "\n",
    "    # Генерация изображения с pipe\n",
    "    images = pipe(\n",
    "        prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        image=controlnet_img,\n",
    "        controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        num_inference_steps=30,\n",
    "        num_images_per_prompt=10\n",
    "    )\n",
    "\n",
    "    # Конвертируем маску в NumPy массив для применения\n",
    "    controlnet_mask = np.array(controlnet_img)\n",
    "\n",
    "    # Пройдем по всем сгенерированным изображениям\n",
    "    for im in range(len(images.images)):\n",
    "        #images.images[im].save(\"./img/\" + t + \"image_\" +random_mask_file[:-4]+\"_\"+ str(im) + '_' + str(i) + \".jpg\")\n",
    "        ###############################\n",
    "        # Получаем сгенерированное изображение как NumPy массив\n",
    "        img_array = np.array(images.images[im])\n",
    "        # Создаем белый фон, такого же размера как изображение\n",
    "        white_background = np.full_like(img_array, 255)\n",
    "        # Применяем маску: где маска черная (0), делаем белым\n",
    "        masked_image = np.where(controlnet_mask[..., None] <100, white_background, img_array)\n",
    "        # Конвертируем обратно в PIL изображение\n",
    "        masked_pil_image = Image.fromarray(masked_image)\n",
    "        # Сохраняем изображение\n",
    "        #masked_pil_image.save(\"./img/\" + t + \"image_\" +random_mask_file[:-4]+\"_\"+ str(im) + '_' + str(i) + \".jpg\")\n",
    "        #############################\n",
    "\n",
    "        # Преобразование PIL Image в NumPy массив с цветовым пространством RGB\n",
    "        image_np = np.array(masked_pil_image.convert('RGB'))\n",
    "        \n",
    "        # Обработка изображения\n",
    "        results = hands.process(image_np)\n",
    "        \n",
    "        # Проверка и получение оценки уверенности\n",
    "        if results.multi_hand_landmarks:\n",
    "            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                # Получение информации о классификации руки\n",
    "                hand_classification = results.multi_handedness[idx]\n",
    "                hand_label = hand_classification.classification[0].label  # 'Left' или 'Right'\n",
    "                hand_score = hand_classification.classification[0].score  # Оценка уверенности (от 0 до 1)\n",
    "                probability = hand_score * 100  # Конвертируем в проценты\n",
    "        \n",
    "                # Вывод информации\n",
    "                print(f\"вероятность {probability:.2f}%\")\n",
    "\n",
    "                masked_pil_image.save(\"./img/\" + t + \"image_\" +random_mask_file[:-4]+\"_\"+ str(im) + '_' + str(i)+f\"_{probability:.2f}\" + \".jpg\")\n",
    "\n",
    "        else:\n",
    "            #masked_pil_image.save(\"./img_b/\" + t + \"image_\" +random_mask_file[:-4]+\"_\"+ str(im) + '_' + str(i) + \".jpg\")\n",
    "            print(\"Рука не обнаружена на изображении.\")\n",
    "    \n",
    "    # Очищаем кэш после каждой итерации\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
